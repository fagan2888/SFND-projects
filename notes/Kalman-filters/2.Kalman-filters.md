## Measurement and Motion
The Kalman Filter represents our distributions by Gaussians and iterates on two main cycles.

The first cycle is the Measurement Update:
1. Requires a product
2. Uses Bayes rule

The second cycle is the Motion Update:
1. Involves a convolution
2. Uses total probability

### Measurement update
Suppose given the current state, we observe a new measurement. The updated state would shift the mean towards the new measurement. The new state is somewhere in the middle between old state and new measurement. Also the certaintly (sigma^2) would be higher than both the previous belief OR the measurement. Intuitively more measurements means more certainty.

Example parameter update:
Let prior ~ N(u, sigma^2), measurement probability ~ N(nu, r^2).
Then the resulting $$ u' = \frac{1}{\sigma^2 + r^2} [r^2 * \mu + \sigma^2 * \nu] $$, and $$ \sigma^2 ' = \frac{1}{1/\sigma^2 + 1/r^2} $$.

Let \mu = 10, \sigma^2 = 4, \nu = 12, r^2 = 4. The result would then be \mu' = 11 and \sigma^2' = 2. Notice that the new mean is somewhere between 10 and 12, and the new variance is LESS (More certain).

What if two gaussians are separated and have the same variance, what would be the result? ANS: exactly in the middle for the new mean, because they had equal variance we just normalizing by the previous equation.

For the variance, always we will have more certainty with more measurements. That means the resulting variance will be smaller (A higher peak for the gaussian).

### Motion update
new mean = old mean + mean of motion
new variance = old var + new var of motion

### Kalman Prediction
Supposed now we have 2D (x,y). Such as a radar detecting a car's position. The 2D KF could infer the velocity without directly measuring it, and incorporates this information into future predictions.

### Multivariate Gaussians
The mean is a vector \mu = [\mu_0 ... \mu_D], the covariance is \Sigma = [ ... ]

Correlation: When the variance in 1 dimension increases, the other variances is believed to also increase (Imagine a tilted elipse representing the covariance matrix).

### Designing KF
Need to know:
1. State transition function
2. Measurement function

For a 1D object:
```
x_prime = x + x_dot*delta_t
```

